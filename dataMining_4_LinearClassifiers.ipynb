{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris, load_boston\n",
    "from sklearn.linear_model import LinearRegression, RidgeClassifier, LogisticRegression, Lasso\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, StratifiedKFold\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Classification\n",
    "\n",
    "Let's first repurpose our regression model to do classification. For this, we will train two classifiers with different label distributions on the training data. We then run both classifiers on the test data, and the one with the higher output \"wins\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get iris data and only select the first two iris species\n",
    "iris = load_iris()\n",
    "X = iris.data[0:100]\n",
    "y = iris.target[0:100]\n",
    "\n",
    "# normalize\n",
    "X = (X-X.mean(axis=0))/X.std(axis=0)\n",
    "\n",
    "# train first classifier\n",
    "lr1 = LinearRegression()\n",
    "lr1.fit(X,y)\n",
    "\n",
    "# train second classifier on inverse labels\n",
    "lr2 = LinearRegression()\n",
    "lr2.fit(X,1-y)\n",
    "\n",
    "# plot the classifier outputs and the true labels\n",
    "fig,ax = plt.subplots(figsize=(8,6))\n",
    "plt.plot(lr1.predict(X),label='classifier 1')\n",
    "plt.plot(lr2.predict(X),label='classifier 2')\n",
    "plt.plot(y,label='true label')\n",
    "plt.legend(loc='best')\n",
    "plt.title('{:.3f}% recognition accuracy'.format(np.size(np.where(((lr1.predict(X)>lr2.predict(X))-y)==0))))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this works pretty well. Of course, as you know by now, we made a big mistake here:\n",
    "\n",
    "** We did not do cross validation!** \n",
    "\n",
    "Our results are therefore most likely \"overfit\". Let's remedy this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get iris data and only select the second two iris species\n",
    "# we know that these are a bit harder to separate!\n",
    "iris = load_iris()\n",
    "X = iris.data[50:]\n",
    "# change the labels from \"1\",\"2\" to \"0\",\"1\"\n",
    "y = iris.target[50:]-1\n",
    "\n",
    "# normalize\n",
    "X = (X-X.mean(axis=0))/X.std(axis=0)\n",
    "\n",
    "# make cross validation splits, taking care to choose the same\n",
    "# amount of classes in each split!\n",
    "CV = StratifiedKFold(n_splits=8)\n",
    "\n",
    "# make a list of accuracy values to be populated \n",
    "acc = list()\n",
    "\n",
    "# init two classifiers\n",
    "lr1 = LinearRegression()\n",
    "lr2 = LinearRegression()\n",
    "\n",
    "# this loops across all splits for the data\n",
    "for train, test in CV.split(X, y):\n",
    "    \n",
    "    # fit the two classifiers\n",
    "    lr1.fit(X[train],y[train])\n",
    "    lr2.fit(X[train],1-y[train])\n",
    "    \n",
    "    # check the accuracy on the test data\n",
    "    acc.append(np.size(np.where(((lr1.predict(X[test])>lr2.predict(X[test]))-y[test])==0))/len(test))\n",
    "\n",
    "print('found mean accuracy of {:.3f}'.format(np.mean(acc)))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, not all splits are able to generate this good performance. Hence, our estimate of 100% accuracy is definitely over-optimistic!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression\n",
    "\n",
    "Here, we will use the `sklearn` implementation for logistic regression (which is a classification algorithm). The implementation is a lot more powerful than we discussed in class, but for now we will force it to do the standard model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acc = list()\n",
    "\n",
    "# init logistic regression - note that the default logistic\n",
    "# regression in sklearn has a regularizer built in on the weights\n",
    "# if we specify a very large \"C\" value, we switch this OFF and\n",
    "# obtain the \"standard\" logistic regression model!\n",
    "logit = LogisticRegression(C=1000000)\n",
    "\n",
    "# this loops across all splits for the data\n",
    "for train, test in CV.split(X, y): \n",
    "    # fit the classifier\n",
    "    logit.fit(X[train],y[train])    \n",
    "    acc.append(logit.score(X[test],y[test]))\n",
    "\n",
    "print('found mean accuracy of {:.3f}'.format(np.mean(acc)))\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that logistic regression is a tiny bit better compared to the linear classifier.\n",
    "\n",
    "Do not be overawed but the 100.0% compared to 91.6% - the amount of examples that are classified better is likely just one! To justify that logistic regression really fares better, we should compare the results on a few more test sets and then do proper statistical testing (t-tests would be fine).  \n",
    "\n",
    "We can also take a look at the class probabilities for one of the test splits, since logistic regression outputs these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(logit.predict_proba(X[test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrons - learning the decision hyperplane\n",
    "\n",
    "Let's try to implement the perceptron according to the DataMining book algorithm.\n",
    "\n",
    "```\n",
    "Set all weights to zero\n",
    "Until all instances in the training data are classified correctly\n",
    "  For each instance I in the training data\n",
    "    If I is classified incorrectly by the perceptron\n",
    "      If I belongs to the first class add it to the weight vector\n",
    "      else subtract it from the weight vector\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the two classes of IRIS data\n",
    "iris = load_iris()\n",
    "\n",
    "firstTwo = True\n",
    "\n",
    "if firstTwo==True:\n",
    "    X = iris.data[:100]\n",
    "    y = iris.target[:100]\n",
    "else:\n",
    "    X = iris.data[50:]\n",
    "    y = iris.target[50:]-1    \n",
    "\n",
    "# normalize\n",
    "X = (X-X.mean(axis=0))/X.std(axis=0)\n",
    "\n",
    "# for the iris data, we have four inputs, so we need 4+1 weights\n",
    "w = np.zeros(5)\n",
    "\n",
    "# everybody classified correctly?\n",
    "allCorrect = False\n",
    "\n",
    "# number of iterations\n",
    "numIter = 0\n",
    "\n",
    "# update weights until everything is correct, or we have reached\n",
    "# maximum number of iterations\n",
    "while (allCorrect==False and numIter<100):\n",
    "    numIter +=1\n",
    "    currCorrect = 0\n",
    "    # go through training examples\n",
    "    for idx,xc in enumerate(X):   \n",
    "        # add the one to the beginning, this is our instance\n",
    "        I = np.hstack((1,xc))\n",
    "        # get the current class\n",
    "        yc = y[idx]\n",
    "        # classify example and check whether it belongs to first class\n",
    "        isFirstClass = np.dot(w,I)>=0     \n",
    "        # check the two correct cases\n",
    "        if (yc == 0 and isFirstClass):\n",
    "            currCorrect += 1\n",
    "        if (yc == 1 and ~isFirstClass):\n",
    "            currCorrect += 1\n",
    "        # update weights for the two incorrect cases\n",
    "        if (yc == 0 and ~isFirstClass):\n",
    "            w += I  \n",
    "        if (yc == 1 and isFirstClass):\n",
    "            w -= I      \n",
    "    print('Iteration',numIter,': classified',currCorrect,'examples correctly')\n",
    "    if currCorrect==len(X):\n",
    "        allCorrect=True\n",
    "\n",
    "print('final weights:',w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works very well and very quickly for the first two IRIS classes, but it does fail to converge on the second two IRIS classes.\n",
    "\n",
    "In the latter case, a few flowers seem to not be linearly separable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron - Version 2\n",
    "\n",
    "Let's implement the second version of the perceptron and add the learning rate according to the class notes.\n",
    "\n",
    "We will therefore update the weights according to:\n",
    "\n",
    "$ w_i = w_i + \\eta (target_i - output_i) x_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the two classes of IRIS data\n",
    "iris = load_iris()\n",
    "\n",
    "firstTwo = True\n",
    "\n",
    "if firstTwo==True:\n",
    "    X = iris.data[:100]\n",
    "    y = iris.target[:100]\n",
    "else:\n",
    "    X = iris.data[50:]\n",
    "    y = iris.target[50:]-1    \n",
    "\n",
    "# normalize\n",
    "X = (X-X.mean(axis=0))/X.std(axis=0)\n",
    "\n",
    "# for the iris data, we have four inputs, so we need 4+1 weights\n",
    "w = np.zeros(5)\n",
    "\n",
    "# everybody classified correctly?\n",
    "allCorrect = False\n",
    "\n",
    "# number of iterations\n",
    "numIter = 0\n",
    "\n",
    "# learning rate\n",
    "eta = 0.02\n",
    "\n",
    "# update weights until everything is correct, or we have reached\n",
    "# maximum number of iterations\n",
    "while (allCorrect==False and numIter<100):\n",
    "    numIter +=1\n",
    "    currCorrect = 0\n",
    "    # go through training examples\n",
    "    for idx,xc in enumerate(X):   \n",
    "        # add the one to the beginning, this becomes our instance I\n",
    "        I = np.hstack((1,xc))\n",
    "        # get the current class\n",
    "        yc = y[idx]\n",
    "        # classify example and produce output\n",
    "        output = 1 if np.dot(w,I)>=0 else 0\n",
    "        # the error is the difference between output and target\n",
    "        error = yc-output\n",
    "        # now check and update weights if necessary\n",
    "        if (error ==0):\n",
    "            currCorrect += 1\n",
    "        else:\n",
    "            w += eta*error*I\n",
    "    print('Iteration',numIter,': classified',currCorrect,'examples correctly')\n",
    "    if currCorrect==len(X):\n",
    "        allCorrect=True\n",
    "\n",
    "print('final weights:',w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works well enough for the first set of iris flowers, but fails to converge fully for the second set just like the previous version of the algorithm that did not include the learning rate.\n",
    "\n",
    "Optimizing the learning rate $\\eta$ is another science in itself. We will come back to this issue, when we talk about multi-layer neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
